{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483d906d",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1a096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import openpyxl as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290b6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "tasks_df = pd.read_csv(\"../original_data/onet_task_statements.csv\") \n",
    "occ_metadata_df = pd.read_excel(\"../new_onet_data/excel/occupation_level_metadata.xlsx\", engine=\"openpyxl\")\n",
    "occ_metadata_df.to_csv(\"../new_onet_data/csv/occupation_level_metadata.csv\", index=False)\n",
    "\n",
    "\n",
    "# Filter to Incumbent and Occupational Expert tasks and get unique job titles\n",
    "relevant_tasks = tasks_df[tasks_df['Domain Source'].isin(['Incumbent', 'Occupational Expert'])][['Title', 'Domain Source']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Filter only rows about experience breakdown\n",
    "occ_metadata_exp_incumbant = occ_metadata_df[occ_metadata_df['Item'] == \"How Long at Current Job\"]\n",
    "occ_metadata_exp_expert = occ_metadata_df[occ_metadata_df['Item'] == \"How Much Experience Performing Work in this Occupation\"]\n",
    "\n",
    "\n",
    "\n",
    "#Pivot it to get a clean format: one row per job title, columns are experience bins\n",
    "occ_metadata_exp_incumbant_pivot = occ_metadata_exp_incumbant.pivot_table(\n",
    "    index=['O*NET-SOC Code', 'Title'],\n",
    "    columns='Response',  # e.g., '1-2 Years', '10+ Years', etc.\n",
    "    values='Percent',          # Use 'N' for count, or 'Percent' for percentage\n",
    "    aggfunc='first'      # Use first if it's guaranteed 1 entry per combo\n",
    ").reset_index()\n",
    "\n",
    "#Pivot it to get a clean format: one row per job title, columns are experience bins\n",
    "occ_metadata_exp_expert_pivot = occ_metadata_exp_expert.pivot_table(\n",
    "    index=['O*NET-SOC Code', 'Title'],\n",
    "    columns='Response',  # e.g., '1-2 Years', '10+ Years', etc.\n",
    "    values='Percent',          # Use 'N' for count, or 'Percent' for percentage\n",
    "    aggfunc='first'      # Use first if it's guaranteed 1 entry per combo\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# Merge source info onto pivoted experience table\n",
    "merged_df_incumbant = pd.merge(occ_metadata_exp_incumbant_pivot, relevant_tasks, on='Title', how='left')\n",
    "merged_df_expert = pd.merge(occ_metadata_exp_expert_pivot, relevant_tasks, on='Title', how='left')\n",
    "\n",
    "occ_level_df = pd.read_excel(\"../new_onet_data/excel/job_zones.xlsx\", engine=\"openpyxl\")\n",
    "occ_level_df.to_csv(\"../new_onet_data/csv/job_zones.csv\", index=False)\n",
    "\n",
    "merged_df_incumbant = pd.merge(merged_df_incumbant, occ_level_df, on='Title', how='left')\n",
    "merged_df_expert = pd.merge(merged_df_expert, occ_level_df, on='Title', how='left')\n",
    "\n",
    "# Sort by '10+ Years' experience column \n",
    "sorted_df_incumbant = merged_df_incumbant.sort_values(by='10 Years or More', ascending=False)\n",
    "sorted_df_incumbant.to_csv(\"../new_data/domain_source_breakdown_incumbant.csv\", index=False)\n",
    "\n",
    "sorted_df_expert = merged_df_expert.sort_values(by='10+ Years', ascending=False)\n",
    "sorted_df_expert.to_csv(\"../new_data/domain_source_breakdown_expert.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2592b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Job Zone for Expert Tasks: 4.01025641025641\n",
      "Average Job Zone for Incumbant Tasks: 2.9306184012066363\n",
      "Expert Job Zone counts:\n",
      "Job Zone\n",
      "4    93\n",
      "5    58\n",
      "3    33\n",
      "2    10\n",
      "1     1\n",
      "Name: count, dtype: int64\n",
      "Incumbent Job Zone counts:\n",
      "Job Zone\n",
      "2    272\n",
      "3    170\n",
      "4    100\n",
      "5     92\n",
      "1     29\n",
      "Name: count, dtype: int64\n",
      "Expert Job Zone percentage breakdown:\n",
      "Job Zone\n",
      "4    47.69\n",
      "5    29.74\n",
      "3    16.92\n",
      "2     5.13\n",
      "1     0.51\n",
      "Name: proportion, dtype: float64\n",
      "Incumbent Job Zone percentage breakdown:\n",
      "Job Zone\n",
      "2    41.03\n",
      "3    25.64\n",
      "4    15.08\n",
      "5    13.88\n",
      "1     4.37\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "expert_level_avg = sorted_df_expert[\"Job Zone\"].mean()\n",
    "incumbant_level_avg = sorted_df_incumbant[\"Job Zone\"].mean()\n",
    "print(f\"Average Job Zone for Expert Tasks: {expert_level_avg}\")\n",
    "print(f\"Average Job Zone for Incumbant Tasks: {incumbant_level_avg}\")\n",
    "\n",
    "# For expert tasks\n",
    "print(\"Expert Job Zone counts:\")\n",
    "print(sorted_df_expert[\"Job Zone\"].value_counts())\n",
    "\n",
    "# For incumbent tasks\n",
    "print(\"Incumbent Job Zone counts:\")\n",
    "print(sorted_df_incumbant[\"Job Zone\"].value_counts())\n",
    "\n",
    "# For expert tasks\n",
    "print(\"Expert Job Zone percentage breakdown:\")\n",
    "print((sorted_df_expert[\"Job Zone\"].value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "# For incumbent tasks\n",
    "print(\"Incumbent Job Zone percentage breakdown:\")\n",
    "print((sorted_df_incumbant[\"Job Zone\"].value_counts(normalize=True) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f87416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 14.372, p-value: 0.00000\n",
      "Chi2: 163.276, p-value: 0.00000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "expert_zones = sorted_df_expert[\"Job Zone\"].dropna()\n",
    "incumbent_zones = sorted_df_incumbant[\"Job Zone\"].dropna()\n",
    "\n",
    "t_stat, p_val = ttest_ind(expert_zones, incumbent_zones, equal_var=False)\n",
    "\n",
    "print(f\"T-statistic: {t_stat:.3f}, p-value: {p_val:.5f}\")\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Build contingency table\n",
    "job_zone_dist = pd.crosstab(index=sorted_df_expert[\"Job Zone\"], columns=\"Expert\")\n",
    "job_zone_dist[\"Incumbent\"] = sorted_df_incumbant[\"Job Zone\"].value_counts()\n",
    "\n",
    "# Run test\n",
    "chi2, p, dof, expected = chi2_contingency(job_zone_dist.fillna(0))\n",
    "\n",
    "print(f\"Chi2: {chi2:.3f}, p-value: {p:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a01491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.457489\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          Source_Binary   No. Observations:                  858\n",
      "Model:                          Logit   Df Residuals:                      856\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 31 Jul 2025   Pseudo R-squ.:                  0.1464\n",
      "Time:                        16:32:07   Log-Likelihood:                -392.53\n",
      "converged:                       True   LL-Null:                       -459.85\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.926e-31\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.2915      0.327    -13.141      0.000      -4.932      -3.651\n",
      "Job Zone       0.8811      0.084     10.519      0.000       0.717       1.045\n",
      "==============================================================================\n",
      "Coefficient: 0.8750\n",
      "Intercept: -4.2685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       663\n",
      "           1       0.39      0.30      0.34       195\n",
      "\n",
      "    accuracy                           0.73       858\n",
      "   macro avg       0.60      0.58      0.58       858\n",
      "weighted avg       0.71      0.73      0.72       858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_expert = sorted_df_expert[[\"Title\", \"Job Zone\"]].copy()\n",
    "df_expert[\"Domain_Source\"] = \"Expert\"\n",
    "\n",
    "df_incumbent = sorted_df_incumbant[[\"Title\", \"Job Zone\"]].copy()\n",
    "df_incumbent[\"Domain_Source\"] = \"Incumbent\"\n",
    "\n",
    "combined_df = pd.concat([df_expert, df_incumbent], ignore_index=True)\n",
    "combined_df = combined_df.dropna(subset=[\"Job Zone\"])\n",
    "\n",
    "# Binary encode\n",
    "combined_df[\"Source_Binary\"] = (combined_df[\"Domain_Source\"] == \"Expert\").astype(int)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = combined_df[[\"Job Zone\"]]\n",
    "y = combined_df[\"Source_Binary\"]\n",
    "\n",
    "model = sm.Logit(y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(f\"Coefficient: {model.coef_[0][0]:.4f}\")\n",
    "print(f\"Intercept: {model.intercept_[0]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Optional: Evaluate\n",
    "preds = model.predict(X)\n",
    "print(classification_report(y, preds))\n",
    "\n",
    "X = sm.add_constant(combined_df[[\"Job Zone\"]])\n",
    "y = combined_df[\"Source_Binary\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
